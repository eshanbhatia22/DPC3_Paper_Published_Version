\section{Prefetcher Configurations}
\label{Config}

This section describes our approach in putting together all the prefetching 
components across the cache hierarchies.

\subsection{Single-Core Configuration}
\label{Config-Single}

\noindent \textbf{L1D Cache:}
For the L1D Cache we are using a modified version of the next-line prefetcher [cite].
\textcolor{blue}{
- Gino to add details about the modification.
- I might add page balancing idea here.
}
All the prefetche suggestions coming from the L1D prefetcher are being placed in L1D Cache.

\noindent \textbf{L2C Cache:}
For the L2C, we are using the enhaced SPP+PPF approach described in the previous section.
\textcolor{blue}{
- Talk about ignoring previous level's prefetch misses or not
}
Prefetches originating from the L2C can be placed in L2C or LLC, depending on the confidence
estimate given by the perceptron sum.

\noindent \textbf{LLC Cache:}
\textcolor{blue}{
- Write something on LLC
}




Here we discuss the various features that correlate the prefetching
decision with the program behavior.  All the features we used can be
derived from the information available in the L2 Cache access stream
or are taken as metadata derived from the baseline prefetcher.  Our
feature selection involved searching over a large space of relevant
perceptron features.  Note that part of the process of tuning PPF to a
specific prefetcher involves examining the available metadata in the
prefetcher itself, and thus PPF is attuned to the baseline
prefetcher's design. Using the statistical methodology outlined in
Section~\ref{Method-Features}, we pruned the feature set to a minimal
yet relevant set of features.

\noindent \textbf{Physical Address}: Here we use the lower bits 
of the physical address of 
the demand access that triggers the prefetch. This address corresponds 
to a  stream of accesses that SPP and the PPF have seen before. 
Therefore, PPF will correlate the past behavior of this address 
to the prefetch outcome. 

\noindent \textbf{Cache Line} and \textbf{Page Address}: These two
separate features are derived from the base address that triggered the
prefetch, as follows: $base\_addr >> LOG2\_BLOCK \_SIZE$ and
$base\_addr >> LOG2\_PAGE\_SIZE$ respectively. The idea behind using
three different shifted versions of the same feature is that it allows
the filter to focus its examination in more detail on different
aspects of the address than with a single version.  It also helps give
more importance to the overlapping bits and lesser importance to most
and least significance bits.  This approach can also eliminate
destructive interference that can be caused by directly folding
the address bits into half.

\noindent \textbf{Program Counter XOR Depth}: The PC is for the
instruction that triggered the prefetch chain.  Depth refers to the
iteration count of the lookahead stages.  By itself, we find the PC to
not be a good basis for filtering a lookahead prefetcher, as all the
prefetches with depth >= 1 are aliased into the same PC, which will
not be the PC of the eventual actual demand access.  This feature
resolves a PC into a different value for each lookahead depth of
prefetch speculation, giving a more accurate correlation in lookahead
cases.  This is akin to the concept of Virtual Program
Counters~\cite{VPC} introduced by Kim \textit{et. al.} for indirect
branch prediction.

\noindent \textbf{PC\textsubscript{1} XOR PC\textsubscript{2}>>1 XOR
  PC\textsubscript{3}>>2}: Here $PC_i$ refers to the last $i^{th}$ PC
before the instruction that triggered the current prefetch.  Hashing
together the last three PCs informs PPF about the path that led to the
current demand access and helps capture and branching information of
the current basic block.  PCs are shifted in the increasing order of
history before being hashed together. This is done to avoid the
resultant value of zero when 2 or more PCs are the same. Additionally,
blurring the information as it gets older allows us to get a wider and
yet more approximate look into the program's history.

\noindent \textbf{Program Counter XOR Delta}: This feature tells us if
a given PC favors particular value(s) of delta.  As noted earlier,
while the PC alone does not convey useful information, this hash
resolves the PC into different values based on the tendency of that PC
to favor a certain delta.  Thus, the dynamic nature of different
instances of the same memory access instruction is captured here.

\noindent \textbf{Confidence}: The confidence, on a scale of 0 to 100,
used to throttle lookahead depth in the original SPP design.  While
the original confidence does not directly make the decision to
prefetch, PPF correlates it to the correctness of a proposed prefetch.
While the original SPP may have dismissed a prefetch due to running
further into speculation, PPF can use the original confidence as
indicator of not only when prefetches become less confident, but also
how likely a low confident speculation is correct in the context of
other features.

\noindent \textbf{Page Address XOR Confidence}: This feature scores
the tendency of each page to be prefetch friendly or prefetch averse.
It helps resolve a page into different entries depending on its
confidence for prefetching, which can vary during phases of a program
execution.

\noindent \textbf{Current Signature XOR Delta}: Recall from the
discussion of SPP in Section~\ref{Background-SPP} that the new
signature is generated using the old signature and the current block
delta.  The result of this feature is the next signature that is
predicted to be accessed based on the delta predicted by SPP. While
``Current Signature XOR Delta'' is not the exact formula for
generating the future signature, it gives an approximate idea of the
path that the combination of these two values can lead to.

As can be noted above, some composite features are derived from simple
hashing (XOR) of two primary features. There is always a question of
usefulness of such composite features and the new information added.
We justify the choice of each feature by quantifying the contribution
made towards predicting prefetch behavior, in Section
\ref{Method-Features}.  Finally, as noted above, each feature indexes
into its independent entry of perceptron weights.
